{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7aeaa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import hashlib\n",
    "import requests\n",
    "from lxml.html import parse\n",
    "\n",
    "if not os.path.exists('.cache'):\n",
    "    os.makedirs('.cache')\n",
    "\n",
    "ua = 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/34.0.1847.116 Safari/537.36'\n",
    "session = requests.Session()\n",
    "\n",
    "def get(url):\n",
    "    '''Return cached lxml tree for url'''\n",
    "    path = os.path.join('.cache', hashlib.md5(url).hexdigest() + '.html')\n",
    "    if not os.path.exists(path):\n",
    "        print (\"url\")\n",
    "        response = session.get(url, headers={'User-Agent': ua})\n",
    "        with open(path, 'w') as fd:\n",
    "            fd.write(response.text.encode('utf-8'))\n",
    "    return parse(open(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3b0a066",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "def process(page):\n",
    "    headers = 'edition,year,venue,round,team1,team2,score'.split(',')\n",
    "    url = 'http://www.linguasport.com/futbol/internacional/mundial/seekff.asp?'\n",
    "    if page > 1:\n",
    "        url += '?pn=%d' % page\n",
    "    tree = get(url)\n",
    "    count = 0\n",
    "    for row in tree.findall('.//tr')[1:]:\n",
    "        cells = [cell.text_content().strip() for cell in row.findall('.//td')]\n",
    "        if len(cells) == 7:\n",
    "            match = dict(zip(headers, cells))\n",
    "            match['url'] = row.find('.//a').get('href')\n",
    "            result.append(match)\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01ecf9c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Strings must be encoded before hashing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m page \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m     count \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m count \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mprocess\u001b[0;34m(page)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m page \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m      7\u001b[0m     url \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m?pn=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m page\n\u001b[0;32m----> 8\u001b[0m tree \u001b[38;5;241m=\u001b[39m \u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.//tr\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m:]:\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124;03m'''Return cached lxml tree for url'''\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.cache\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mhashlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmd5\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhexdigest() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.html\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(path):\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Strings must be encoded before hashing"
     ]
    }
   ],
   "source": [
    "page = 1\n",
    "while True:\n",
    "    count = process(page)\n",
    "    if count == 0:\n",
    "        break\n",
    "    else:\n",
    "        page += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1ed877",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(result)\n",
    "data.to_csv('matches.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56450c79",
   "metadata": {},
   "source": [
    "\n",
    "Scrape goal-level data\n",
    "\n",
    "We're restricting ourselves to the FS (final stage) details pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7352d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = set([url.split('#')[0] for url in data['url'].unique() if '_FS' in url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3919b378",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_space = re.compile(r'\\s+', re.DOTALL)\n",
    "re_goals = re.compile(r'(\\d)\\-(\\d) +\\((\\D+)([\\d\\+]+).*?\\)', re.DOTALL)\n",
    "head_goals = 'team1score,team2score,player,minute'.split(',')\n",
    "re_books = re.compile(r'([^\\(]+)\\(.*?([\\d\\+]+).*?\\) *[,/]', re.DOTALL)\n",
    "head_books = 'player,minute'.split(',')\n",
    "\n",
    "base = 'http://www.linguasport.com/futbol/internacional/mundial/'\n",
    "goals = []\n",
    "games = []\n",
    "books = []\n",
    "for url in urls:\n",
    "    tree = get(base + url)\n",
    "    for table in tree.findall('.//table[@class=\"MsoNormalTable\"]'):\n",
    "        game = {\n",
    "            'url': url,\n",
    "            'stage': table.find('.//tr[1]//td').text_content()\n",
    "        }\n",
    "        games.append(game)\n",
    "        game['game_id'] = len(games)\n",
    "        for para in table.findall('.//tr[2]//p'):\n",
    "            text = para.text_content().strip()\n",
    "            match = re.match(r'([A-Z]+): +(.*)', text, re.DOTALL)\n",
    "            if match:\n",
    "                game[match.group(1)] = re_space.sub(' ', match.group(2)).strip()\n",
    "            if 'ATTENDANCE' in game:\n",
    "                game['ATTENDANCE'] = game['ATTENDANCE'].replace('.', '')\n",
    "            if 'GOALS' in game:\n",
    "                for matches in re_goals.findall(game['GOALS']):\n",
    "                    goal = dict(zip(head_goals, [m.strip() for m in matches]))\n",
    "                    goal['game_id'] = game['game_id']\n",
    "                    goals.append(goal)\n",
    "                del game['GOALS']\n",
    "            if 'BOOKED' in game:\n",
    "                for matches in re_books.findall(game['BOOKED']):\n",
    "                    book = dict(zip(head_books, [m.strip() for m in matches]))\n",
    "                    book['game_id'] = game['game_id']\n",
    "                    books.append(book)\n",
    "                del game['BOOKED']\n",
    "        teams = re_space.sub(' ', table.find('.//tr[3]//td[3]').text_content())\n",
    "        teams = teams.replace(u'\\xe2\\x80\\x93', '-').strip().split(' - ')\n",
    "        if len(teams) == 2:\n",
    "            game['team1'], game['team2'] = teams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916476f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(games).to_csv('games.csv', index=False, encoding='utf-8')\n",
    "pd.DataFrame(goals).to_csv('goals.csv', index=False, encoding='utf-8')\n",
    "pd.DataFrame(books).to_csv('books.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
