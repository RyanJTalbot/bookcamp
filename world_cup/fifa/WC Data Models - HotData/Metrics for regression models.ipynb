{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics for regression models\n",
    "\n",
    "The metrics returned for regression models are designed to estimate the amount of error. A\n",
    "model is considered to fit the data well if the difference between observed and predicted values is small. However, looking at the pattern of the residuals (the difference between any one predicted point and its corresponding actual value) can tell you a lot about potential bias in the model. \n",
    "\n",
    "\n",
    "The following metrics are reported for evaluating regression models.\n",
    "\n",
    "- <b>Mean absolute error (MAE)</b> measures how close the predictions are to the actual outcomes; thus, a lower score is better.\n",
    "\n",
    "- <b>Root mean squared error (RMSE)</b> creates a single value that summarizes the error in the model. By squaring the difference, the metric disregards the difference between over- prediction and under-prediction.\n",
    "\n",
    "- <b>Relative absolute error (RAE)</b> is the relative absolute difference between expected and actual values; relative because the mean difference is divided by the arithmetic mean.\n",
    "\n",
    "- <b>Relative squared error (RSE)</b> similarly normalizes the total squared error of the predicted values by dividing by the total squared error of the actual values.\n",
    "\n",
    "- <b> R^2</b> aka <b>Coefficient of determination</b>, often referred to as R2, represents the predictive power of the model as a value between 0 and 1. Zero means the model is random (explains nothing); 1 means there is a perfect fit. However, caution should be used in interpreting R2 values, as low values can be entirely normal and high values can be suspect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AIC stands for (Akaikeâ€™s Information Criteria), a metric developped by the Japanese Statistician, Hirotugu Akaike, 1970. The basic idea of AIC is to penalize the inclusion of additional variables to a model. It adds a penalty that increases the error when including additional terms. The lower the AIC, the better the model.\n",
    "- AICc is a version of AIC corrected for small sample sizes.\n",
    "- BIC (or Bayesian information criteria) is a variant of AIC with a stronger penalty for including additional variables to the model.\n",
    "- Mallows Cp: A variant of AIC developed by Colin Mallows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, the most commonly used metrics, for measuring regression model quality and for comparing models, are: \n",
    "- Adjusted R2 \n",
    "- AIC \n",
    "- BIC  \n",
    "- Cp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
