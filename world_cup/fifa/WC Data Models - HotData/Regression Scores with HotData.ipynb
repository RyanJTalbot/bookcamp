{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosted Decision Tree Regression\n",
    "- MAPE: 0.4760492028207783 feature outliers\n",
    "- MAPE: 0.494226255170061  w/o outliers\n",
    "- MAPE: 0.624914320659015\n",
    "- MAPE: 0.9267041998678649 238\n",
    "- MAPE: 0.8422677384166671 pca\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RIDGE REGRESSION \n",
    "- MAPE: 0.5060373413778145 w/o outliers\n",
    "- MAPE: 0.5278855575455652 feature outliers\n",
    "- MAPE: 0.639088137269967\n",
    "- MAPE: 0.8413063736092469 238\n",
    "- MAPE: 0.7359668945089713 pca\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisson Regression \n",
    "- MAPE: 0.511138203185358 w/o outliers\n",
    "- MAPE: 0.523532396197583\n",
    "- MAPE: 0.5713497732459283\n",
    "- MAPE: 0.8343260186519138\n",
    "- MAPE: 0.650838268824772 pca\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression \n",
    "\n",
    "- MAPE: 0.5112505462494125 w/o outliers\n",
    "- MAPE: 0.5376408392113041 feature outliers\n",
    "- MAPE: 0.6530295467675703\n",
    "- MAPE: 0.7393717490065653 pca\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theil Sen Regressor  (varies slightly)\n",
    "- MAPE: 0.513435420678226 w/o outliers\n",
    "- MAPE: 0.6391671023627005\n",
    "- MAPE: 0.5413330090738759 feature outliers\n",
    "- MAPE: 0.7251086506472615 PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Lars IC \n",
    "- MAPE: 0.5148741993011815 w/o outliers\n",
    "- MAPE: 0.5392336541761028 feature outliers\n",
    "- MAPE: 0.6726834633362502\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression \n",
    "- MAPE: 0.5199759309105587 w/o outliers\n",
    "- MAPE: 0.9514291352862517 feature outliers\n",
    "- MAPE: 32405900060.375282\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orthogonal Matching Pursuit \n",
    "- MAPE: 0.5238823290117006\n",
    "- MAPE: 0.5545636746065563\n",
    "- MAPE: 0.6629570490262351"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweedie Regressor\n",
    "- MAPE: 0.5285899988666015 w/o outliers\n",
    "- MAPE: 0.555185573317258\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Regression \n",
    "- MAPE: 0.5372884910792647 w/o outliers\n",
    "- MAPE: 0.5705654459631618\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QuantileRegressor \n",
    "- MAPE: 0.5521909912065068 w/o outliers\n",
    "- MAPE: 0.6086054283082704\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELASTIC NET \n",
    "- MAPE: 0.5391731926724728 w/o outliers\n",
    "- MAPE: 0.6790582811959258\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hist Gradient Boosting Regressor\n",
    "(used instead of gradient boosting regression)\n",
    "* MAPE: 0.6185506734186609\n",
    "- MAPE: 0.6230792134745115 w/o outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARD Regression \n",
    "- MAPE: 0.6122040799910263\n",
    "- MAPE: 0.8721863097315258 w/o outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression CV\n",
    "- MAPE: 0.759911836717753\n",
    "- MAPE: 1.240901137923022 w/o outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRADIENT BOOSTING REGRESSION \n",
    "- MAPE: 0.6700146435454999 w/o outliers\n",
    "- MAPE: 0.7627028216195546\n",
    "- varies moderatly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECISION FOREST REGRESSION \n",
    "\n",
    "- MAPE: 0.7718338993775256\n",
    "- MAPE: 0.8183446431987169 w/o outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron \n",
    "- MAPE: 0.7787612774552056\n",
    "- MAPE: 1.0203095494667893 w/o outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Ridge \n",
    "- MAPE: 0.9961569267616496 w/o outliers\n",
    "- MAPE: 1.3539389063622675\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Stochastic Gradient Descent Regression \n",
    "\n",
    "- MAPE: 1.3205058526063902\n",
    "- MAPE: 1.029191408765773 w/o outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passive Aggressive Regressor !\n",
    "varies wildly\n",
    "- MAPE: 0.5509611492449589"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- R Square \n",
    "    - <b>value is between 0 to 1 and a bigger value indicates a better fit</b> between prediction and actual value.\n",
    "- MSE \n",
    "    - <b>An ideal Mean Squared Error (MSE) value is 0.0,</b> which means that all predicted values matched the expected values exactly. MSE gives larger penalization to big prediction error by square it while MAE treats all errors the same.\n",
    "- RMSE \n",
    "    - Based on a rule of thumb, it can be said that <b>RMSE values between 0.2 and 0.5 </b>shows that the model can relatively predict the data accurately. In addition, <b>Adjusted R-squared more than 0.75 is a very good</b> value for showing the accuracy. In some cases, Adjusted R-squared of 0.4 or more is acceptable as well.\n",
    "- MAE \n",
    "    - <b>The lower the MAE score the better.</b> This is because MAE is a measure of the average error between the predictions and intended targets, thus we want to minimise this value.\n",
    "\n",
    "\n",
    "- There is no ideal value for MAE as it is returned on the same scale that you are predicting, so an ideal MAE value for one dataset will not be the same for another.\n",
    "- MAE cannot be compared across different models and datasets. However, by converting MAE to MAPE (Mean Absolute Percentage Error), it becomes possible to compare model performance as this error is returned as a percentage.\n",
    "\n",
    "\n",
    "- https://stephenallwright.com/good-mae-score/\n",
    "- https://stephenallwright.com/good-mape-score/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
